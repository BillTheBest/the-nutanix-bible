<div data-type="part">
<h1>Book of Prism</h1>

<p class='definition'><strong>prism - /'prizɘm/ - noun - control plane</strong>
<br/>
one-click management and interface for datacenter operations.</p>

<section data-type="chapter">
<h1>Architecture</h1>

<p>Prism is a distributed resource management platform which allows users to manage and monitor objects and services across their Nutanix environment.</p>

<p>These capabilities are broken down into two key categories:</p>

<ul>
	<li>Interfaces
	<ul>
		<li>HTML5 UI, REST API, CLI, PowerShell CMDlets, etc.</li>
	</ul>
	</li>
	<li>Management
	<ul>
		<li>Policy definition and compliance, service design and status, analytics and monitoring</li>
	</ul>
	</li>
</ul>

<p>The figure highlights an image illustrating the conceptual nature of Prism as part of the Nutanix platform:</p>

<figure><img alt="" class="iimagesv2arch_prismpng" src="imagesv2/arch_prism.png" />
<figcaption>High-Level Prism Architecture</figcaption>
</figure>

<p>Prism is broken down into two main components:</p>

<ul>
	<li>Prism Central (PC)
	<ul>
		<li>Multi-cluster manager responsible for managing multiple Acropolis clusters to provide a single, centralized management interface. &nbsp;Prism Central is an optional software appliance (VM) which can be deployed in addition to the Acropolis cluster (can run on it).</li>
		<li>1-to-many cluster manager</li>
	</ul>
	</li>
	<li>Prism Element (PE)
	<ul>
		<li>Localized cluster manager responsible for local cluster management and operations. &nbsp;Every Acropolis cluster has Prism Element built-in.</li>
		<li>1-to-1 cluster manager</li>
	</ul>
	</li>
</ul>

<p>The figure shows an image illustrating the conceptual relationship between Prism Central and Prism Element:</p>

<figure><img alt="" class="iimagesv2prism_arch2png" src="imagesv2/prism_arch2.png" />
<figcaption>Prism Architecture</figcaption>
</figure>

<div data-type="note" class="note">
<h1>Pro tip</h1>

<p>For larger or distributed deployments (e.g. more than one cluster or multiple sites) it is recommended to use Prism Central to simplify operations and provide a single management UI for all clusters / sites.</p>
</div>

<h1>Prism Services</h1>

<p>A Prism service runs on every CVM with an elected Prism Leader which is responsible for handling HTTP requests.&nbsp; Similar to other components which have a Master, if the Prism Leader fails, a new one will be elected. &nbsp;When a CVM which is not the Prism Leader gets a HTTP request it will permanently redirect the request to the current Prism Leader using HTTP response status code 301.</p>

<p>Here we show a conceptual view of the Prism services and how HTTP request(s) are handled:</p>

<figure><img alt="" class="iimagesv2prism_services3png" src="imagesv2/prism_services3.png" />
<figcaption>Prism Services - Request Handling</figcaption>
</figure>

<div data-type="note" class="note">
<h1>Prism ports</h1>

<p>Prism listens on ports 80 and 9440, if HTTP traffic comes in on port 80 it is redirected to HTTPS on port 9440.</p>
</div>

<p>When using the cluster external IP (recommended),&nbsp;it will always be hosted by the current Prism Leader. &nbsp;In the event of a Prism Leader failure the cluster IP will be assumed by the newly elected Prism Leader and a gratuitous ARP (gARP) will be used to clean any stale ARP cache entries. &nbsp;In this scenario any time the cluster IP is used to access Prism, no redirection is necessary as that will already be the Prism Leader.</p>

<div data-type="note" class="note">
<h1>Pro tip</h1>

<p>You can determine the current Prism leader by running 'curl localhost:2019/prism/leader' on any CVM.</p>
</div>
</section>

<section data-type="chapter">
<h1>Navigation</h1>

<p>Prism is fairly straight forward and simple to use, however we'll cover some of the main pages and basic usage.</p>

<p>Prism Central (if deployed) can be accessed using the IP address specified during configuration or corresponding DNS entry. &nbsp;Prism Element can be accessed via Prism Central (by clicking on a specific cluster) or by navigating to any Nutanix CVM or cluster IP (preferred).</p>

<p>Once the page has been loaded you will be greeted with the Login page where you will use your Prism or Active Directory credentials to login.</p>

<figure><img alt="" class="iimagesv2prismprism_loginpng" src="imagesv2/Prism/prism_login.png" />
<figcaption>Prism Login Page</figcaption>
</figure>

<p>Upon successful login you will be sent to the dashboard page which will provide overview information for managed cluster(s) in Prism Central or the local cluster in Prism Element.</p>

<p>Prism Central and Prism Element will be covered in more detail in the following sections.</p>

<section data-type="sect1">
<h1>Prism Central</h1>

<p>Prism Central contains the following main pages:</p>

<ul>
	<li>Home Page
	<ul>
		<li>Environment wide monitoring dashboard including detailed information on service status, capacity planning, performance, tasks, etc. &nbsp;To get further information on any of them you can click on the item of interest.</li>
	</ul>
	</li>
	<li>Explore Page
	<ul>
		<li>Management and monitoring of services, cluster, VMs and hosts</li>
	</ul>
	</li>
	<li>Analysis Page
	<ul>
		<li>Detailed performance analysis for cluster and managed objects with event correlation</li>
	</ul>
	</li>
	<li>Alerts
	<ul>
		<li>Environment wide alerts</li>
	</ul>
	</li>
</ul>

<p>The figure shows a sample Prism Central dashboard where multiple clusters can be monitored / managed:</p>

<figure class="large"><img alt="" class="iimagesv2prismpc_dashboard2png" src="imagesv2/Prism/PC_dashboard2.png" />
<figcaption>Prism Central - Dashboard</figcaption>
</figure>

<p>From here you can monitor the overall status of your environment, and dive deeper if there are any alerts or items of interest.</p>

<div data-type="note" class="note">
<h1>Pro tip</h1>

<p>If everything is green, go back to doing something else :)</p>
</div>
</section>

<section data-type="sect1">
<h1>Prism Element</h1>

<p>Prism Element contains the following main pages:</p>

<ul>
	<li>Home Page
	<ul>
		<li>Local cluster monitoring dashboard including detailed information on alerts, capacity, performance, health, tasks, etc. &nbsp;To get further information on any of them you can click on the item of interest.</li>
	</ul>
	</li>
	<li>Health Page
	<ul>
		<li>Environment, hardware and managed object health and state information. &nbsp;Includes NCC health check status as well.</li>
	</ul>
	</li>
	<li>VM Page
	<ul>
		<li>Full VM management, monitoring and CRUD (Acropolis)</li>
		<li>VM monitoring (non-Acropolis)</li>
	</ul>
	</li>
	<li>Storage Page
	<ul>
		<li>Container management, monitoring and CRUD</li>
	</ul>
	</li>
	<li>Hardware
	<ul>
		<li>Server, disk and network management,&nbsp;monitoring and health. &nbsp;Includes cluster expansion as well as node and disk removal.</li>
	</ul>
	</li>
	<li>Data Protection
	<ul>
		<li>DR, Cloud Connect and Metro Availability configuration. &nbsp;Management of PD objects,&nbsp;snapshots, replication and restore.</li>
	</ul>
	</li>
	<li>Analysis
	<ul>
		<li>Detailed performance analysis for cluster and managed objects with event correlation</li>
	</ul>
	</li>
	<li>Alerts
	<ul>
		<li>Local cluster and environment alerts</li>
	</ul>
	</li>
</ul>

<p>The home page will provide detailed information on alerts, service status, capacity, performance, tasks, and much more. &nbsp;To get further information on any of them you can click on the item of interest.</p>

<p>The figure shows a sample Prism Element dashboard where local cluster details are displayed:</p>

<figure class="large"><img alt="" class="iimagesv2prismpe_dashboardpng" src="imagesv2/Prism/PE_dashboard.png" />
<figcaption>Prism Element - Dashboard</figcaption>
</figure>

<div data-type="note" class="note">
<h1>Keyboard Shortcuts</h1>

<p>Accessibility and ease of use is a very critical construct in Prism. &nbsp;To simplify things for the end-user a set of shortcuts have been added to allow users to do everything from their keyboard.</p>

<p>The following characterizes some of the key shortcuts:</p>

<p>Change view (page context aware):</p>

<ul>
	<li>O - Overview View</li>
	<li>D - Diagram View</li>
	<li>T - Table View</li>
</ul>

<p>Activities and Events:</p>

<ul>
	<li>A - Alerts</li>
	<li>P - Tasks</li>
</ul>

<p>Drop down and Menus (Navigate selection using arrow keys):</p>

<ul>
	<li>M - Menu drop-down</li>
	<li>S - Settings (gear icon)</li>
	<li>F - Search bar</li>
	<li>U - User drop down</li>
	<li>H - Help</li>
</ul>
</div>
</section>
</section>

<section data-type="chapter">
<h1>Usage and Troubleshooting</h1>

<p>In the following sections we're cover some of the typical Prism uses as well as some common troubleshooting scenarios.</p>

<section data-type="sect1">
<h1>Nutanix Software Upgrade</h1>

<p>Performing a Nutanix software upgrade is a very simple and non-disruptive process.</p>

<p>To begin, start by logging into Prism and clicking on the gear icon on the top right (settings) or by pressing 'S' and selecting 'Upgrade Software':</p>

<figure><img alt="" class="iimagesv2prismupgradeupgrade_1png" src="imagesv2/Prism/upgrade/upgrade_1.png" />
<figcaption>Prism - Settings - Upgrade Software</figcaption>
</figure>

<p>This will launch the 'Upgrade Software' dialog box and will show your current software version and if there are any upgrade versions available. &nbsp;It is also possible to manually upload a NOS binary file.</p>

<p>You can then download the upgrade version from the cloud or upload the version manually:</p>

<figure><img alt="" class="iimagesv2prismupgradeupgrade_2png" src="imagesv2/Prism/upgrade/upgrade_2.png" />
<figcaption>Upgrade Software - Main</figcaption>
</figure>

<p>It will then upload the upgrade software onto the Nutanix CVMs:</p>

<figure><img alt="" class="iimagesv2prismupgradeupgrade_3png" src="imagesv2/Prism/upgrade/upgrade_3.png" />
<figcaption>Upgrade Software - Upload</figcaption>
</figure>

<p>After the software is loaded click on 'Upgrade' to start the upgrade process:</p>

<figure><img alt="" class="iimagesv2prismupgradeupgrade_4png" src="imagesv2/Prism/upgrade/upgrade_4.png" />
<figcaption>Upgrade Software - Upgrade Validation</figcaption>
</figure>

<p>You'll then be prompted with a confirmation box:</p>

<figure><img alt="" class="iimagesv2prismupgradeupgrade_5png" src="imagesv2/Prism/upgrade/upgrade_5.png" />
<figcaption>Upgrade Software - Confirm Upgrade</figcaption>
</figure>

<p>The upgrade will start with pre-upgrade checks then start upgrading the software in a rolling manner:</p>

<figure><img alt="" class="iimagesv2prismupgradeupgrade_6png" src="imagesv2/Prism/upgrade/upgrade_6.png" />
<figcaption>Upgrade Software - Execution</figcaption>
</figure>

<p>Once the upgrade is complete you'll see an updated status and have access to all of the new features:</p>

<figure><img alt="" class="iimagesv2prismupgradeupgrade_7png" src="imagesv2/Prism/upgrade/upgrade_7.png" />
<figcaption>Upgrade Software - Complete</figcaption>
</figure>

<div data-type="note" class="note">
<h1>Note</h1>

<p>Your Prism session will briefly disconnect during the upgrade when the current Prism Leader is upgraded. &nbsp;All VMs and services running remain unaffected.</p>
</div>
</section>

<section data-type="sect1">
<h1>Hypervisor Upgrade</h1>

<p>Similar to Nutanix software upgrades, hypervisor upgrades can be fully automated in a rolling manner via Prism.</p>

<p>To begin follow the similar steps above to launch the 'Upgrade Software' dialogue box and select 'Hypervisor'.</p>

<p>You can then download the hypervisor upgrade version from the cloud or upload the version manually:</p>

<figure><img alt="" class="iimagesv2prismupgradehyp_upgrade_1png" src="imagesv2/Prism/upgrade/hyp_upgrade_1.png" />
<figcaption>Upgrade Hypervisor - Main</figcaption>
</figure>

<p>It will then load the upgrade software onto the Hypervisors. &nbsp;After the software is loaded click on 'Upgrade' to start the upgrade process:</p>

<figure><img alt="" class="iimagesv2prismupgradehyp_upgrade_2png" src="imagesv2/Prism/upgrade/hyp_upgrade_2.png" />
<figcaption>Upgrade Hypervisor - Upgrade Validation</figcaption>
</figure>

<p>You'll then be prompted with a confirmation box:</p>

<figure><img alt="" class="iimagesv2prismupgradehyp_upgrade_3png" src="imagesv2/Prism/upgrade/hyp_upgrade_3.png" />
<figcaption>Upgrade Hypervisor - Confirm Upgrade</figcaption>
</figure>

<p>The system will then go through host pre-upgrade checks and upload the hypervisor upgrade to the cluster:</p>

<figure><img alt="" class="iimagesv2prismupgradehyp_upgrade_4png" src="imagesv2/Prism/upgrade/hyp_upgrade_4.png" />
<figcaption>Upgrade Hypervisor - Pre-upgrade Checks</figcaption>
</figure>

<p>Once the pre-upgrade checks are complete the rolling hypervisor upgrade will then proceed:</p>

<figure><img alt="" class="iimagesv2prismupgradehyp_upgrade_5png" src="imagesv2/Prism/upgrade/hyp_upgrade_5.png" />
<figcaption>Upgrade Hypervisor - Execution</figcaption>
</figure>

<p>Similar to the rolling nature of the Nutanix software upgrades, each host will be upgraded in a rolling manner with zero impact to running VMs. &nbsp;VMs will be live-migrated off the current host, the host will be upgraded, and then rebooted. &nbsp;This process will iterate through each host until all hosts in the cluster are upgraded.</p>

<div data-type="note" class="note">
<h1>Pro tip</h1>

<p>You can also get cluster wide upgrade status from any Nutanix CVM by running 'host_upgrade --status'. &nbsp;The detailed per host status is logged to ~/data/logs/host_upgrade.out on each CVM.</p>
</div>

<p>Once the upgrade is complete you'll see an updated status and have access to all of the new features:</p>

<figure><img alt="" class="iimagesv2prismupgradehyp_upgrade_6png" src="imagesv2/Prism/upgrade/hyp_upgrade_6.png" />
<figcaption>Upgrade Hypervisor - Complete</figcaption>
</figure>

</section>

<section data-type="sect1">
<h1>Cluster Expansion (add node)</h1>

<p>Coming soon!</p>
</section>

<section data-type="sect1">
<h1>Capacity Planning</h1>

<p>To get detailed capacity planning details you can click on a specific cluster under the 'cluster runway' section in Prism Central to get more details:</p>

<figure class="large"><img alt="" class="iimagesv2prismpc_capplannerpng" src="imagesv2/Prism/pc_capplanner.png" />
<figcaption>Prism Central - Capacity Planning</figcaption>
</figure>

<p>This view provides detailed information on cluster runway and identifies the most constrained resource (limiting resource). &nbsp;You can also get detailed information on what the top consumers are as well as some potential options to clean up additional capacity or ideal node types for cluster expansion.</p>

<figure><img alt="" class="iimagesv2prismpc_recommendationpng" src="imagesv2/Prism/pc_recommendation.png" />
<figcaption>Prism Central - Capacity Planning - Recommendations</figcaption>
</figure>
</section>

<p>The HTML5 UI is a key part to Prism to provide a simple, easy to use management interface. &nbsp;However, another core ability are the APIs which are available for automation. &nbsp;All functionality exposed through the Prism UI is also exposed through a full set of REST APIs to allow for the ability to programmatically interface with the Nutanix platform. &nbsp;This allow customers and partners to enable automation, 3rd-party tools, or even create their own UI. &nbsp;</p>

<p>The following section covers these interfaces and provides some example usage.</p>
</section>

<section data-type="chapter">
<h1>APIs and Interfaces</h1>

<p>Core to any dynamic or “software-defined” environment, Nutanix provides a vast array of interfaces allowing for simple programability and interfacing. Here are the main interfaces:</p>

<ul>
	<li>REST API</li>
	<li>CLI - ACLI &amp; NCLI</li>
	<li>Scripting interfaces</li>
</ul>

<p>Core to this is the REST API which exposes every capability and data point of the Prism UI and allows for orchestration or automation tools to easily drive Nutanix action.&nbsp; This enables tools like vRealize Operations, System Center Orchestrator, Ansible, SALT, etc.&nbsp;to easily create custom workflows for Nutanix. Also, this means that any third-party developer could create their own custom UI and pull in Nutanix data via REST.</p>

<p>The following figure shows a small snippet of the Nutanix REST API explorer which allows developers to interact with the API and see expected data formats:</p>

<figure class="large"><img alt="" class="iimagesv2restapipng" src="imagesv2/RestAPI.png" />
<figcaption>REST API Explorer</figcaption>
</figure>

<p>Operations can be expanded to display details and examples of the REST call:</p>

<figure class="large"><img alt="" class="iimagesv2restapi2png" src="imagesv2/RestAPI2.png" />
<figcaption>REST API Sample Call</figcaption>
</figure>

<div data-type="note" class="note">
<h1>API Authentication Scheme(s)</h1>

<p>As of 4.5.x basic authentication over HTTPS is leveraged for client and HTTP call authentication.</p>
</div>

<section data-type="sect1">
<h1>ACLI</h1>

<p>The Acropolis CLI (ACLI) is the CLI for managing the Acropolis portion of the Nutanix product. &nbsp;These capabilities were enabled in releases after 4.1.2.</p>

<p>NOTE: All of these actions can be performed via the HTML5 GUI and REST API.&nbsp; I just use these commands as part of my scripting to automate tasks.</p>

<h2>Enter ACLI shell</h2>

<p class="codedescription">Description: Enter ACLI shell (run from any CVM)</p>

<p class="codetext">Acli</p>

<p>OR</p>

 <p class="codedescription">Description: Execute ACLI command via Linux shell</p>

<p class="codetext">ACLI &lt;Command&gt;</p>

<h2>Output ACLI response in json format</h2>

 <p class="codedescription">Description: Lists Acropolis nodes in the cluster.</p>

<p class="codetext">Acli –o json</p>

<h2>List hosts</h2>

 <p class="codedescription">Description: Lists Acropolis nodes in the cluster.</p>

<p class="codetext">host.list</p>

<h2>Create network</h2>

 <p class="codedescription">Description: Create network based on VLAN</p>

<p class="codetext">net.create &lt;TYPE&gt;.&lt;ID&gt;[.&lt;VSWITCH&gt;] ip_config=&lt;A.B.C.D&gt;/&lt;NN&gt;</p>

<p class="codetext">Example: net.create vlan.133 ip_config=10.1.1.1/24</p>

<h2>List network(s)</h2>

 <p class="codedescription">Description: List networks</p>

<p class="codetext">net.list</p>

<h2>Create DHCP scope</h2>

 <p class="codedescription">Description: Create dhcp scope</p>

<p class="codetext">net.add_dhcp_pool &lt;NET NAME&gt; start=&lt;START IP A.B.C.D&gt; end=&lt;END IP W.X.Y.Z&gt;</p>

<p class="note">Note: .254 is reserved and used by the Acropolis DHCP server if an address for the Acropolis DHCP server wasn’t set during network creation</p>

<p class="codetext">Example: net.add_dhcp_pool vlan.100 start=10.1.1.100 end=10.1.1.200</p>

<h2>Get an existing networks details</h2>

 <p class="codedescription">Description: Get a network's properties</p>

<p class="codetext">net.get &lt;NET NAME&gt;</p>

<p class="codetext">Example: net.get vlan.133</p>

<h2>Get an existing networks details</h2>

 <p class="codedescription">Description: Get a network's VMs and details including VM name / UUID, MAC address and IP</p>

<p class="codetext">net.list_vms &lt;NET NAME&gt;</p>

<p class="codetext">Example: net.list_vms vlan.133</p>

<h2>Configure DHCP DNS servers for network</h2>

 <p class="codedescription">Description: Set DHCP DNS</p>

<p class="codetext">net.update_dhcp_dns &lt;NET NAME&gt; servers=&lt;COMMA SEPARATED DNS IPs&gt; domains=&lt;COMMA SEPARATED DOMAINS&gt;</p>

<p class="codetext">Example: net.set_dhcp_dns vlan.100 servers=10.1.1.1,10.1.1.2 domains=splab.com</p>

<h2>Create Virtual Machine</h2>

 <p class="codedescription">Description: Create VM</p>

<p class="codetext">vm.create &lt;COMMA SEPARATED VM NAMES&gt; memory=&lt;NUM MEM MB&gt; num_vcpus=&lt;NUM VCPU&gt; num_cores_per_vcpu=&lt;NUM CORES&gt; ha_priority=&lt;PRIORITY INT&gt;</p>

<p class="codetext">Example: vm.create testVM memory=2G num_vcpus=2</p>

<h2>Bulk Create Virtual Machine</h2>

 <p class="codedescription">Description: Create bulk VM</p>

<p class="codetext">vm.create &nbsp;&lt;CLONE PREFIX&gt;[&lt;STARTING INT&gt;..&lt;END INT&gt;]&nbsp;memory=&lt;NUM MEM MB&gt; num_vcpus=&lt;NUM VCPU&gt; num_cores_per_vcpu=&lt;NUM CORES&gt; ha_priority=&lt;PRIORITY INT&gt;</p>

<p class="codetext">Example: vm.create testVM[000..999]&nbsp;memory=2G num_vcpus=2</p>

<h2>Clone VM from existing</h2>

 <p class="codedescription">Description: Create clone of existing VM</p>

<p class="codetext">vm.clone &lt;CLONE NAME(S)&gt; clone_from_vm=&lt;SOURCE VM NAME&gt;</p>

<p class="codetext">Example: vm.clone testClone clone_from_vm=MYBASEVM</p>

<h2>Bulk Clone VM from existing</h2>

 <p class="codedescription">Description: Create bulk clones of existing VM</p>

<p class="codetext">vm.clone &lt;CLONE PREFIX&gt;[&lt;STARTING INT&gt;..&lt;END INT&gt;] clone_from_vm=&lt;SOURCE VM NAME&gt;</p>

<p class="codetext">Example: vm.clone testClone[001..999]&nbsp;clone_from_vm=MYBASEVM</p>

<h2>Create disk and add to VM</h2>

<p class="codetext"># Description: Create disk for OS</p>

<p class="codetext">vm.disk_create &lt;VM NAME&gt; create_size=&lt;Size and qualifier, e.g. 500G&gt; container=&lt;CONTAINER NAME&gt;</p>

<p class="codetext"> class="codetext"Example: vm.disk_create testVM create_size=500G container=default</p>

<h2>Add NIC to VM</h2>

 <p class="codedescription">Description: Create and add NIC</p>

<p class="codetext">vm.nic_create &lt;VM NAME&gt; network=&lt;NETWORK NAME&gt; model=&lt;MODEL&gt;</p>

<p class="codetext">Example: vm.nic_create testVM network=vlan.100</p>

<h2>Set VM’s boot device to disk</h2>

 <p class="codedescription">Description: Set a VM boot device</p>

<p>Set to boot form specific disk id</p>

<p class="codetext">vm.update_boot_device &lt;VM NAME&gt; disk_addr=&lt;DISK BUS&gt;</p>

<p class="codetext">Example: vm.update_boot_device testVM disk_addr=scsi.0</p>

<h2>Set VM’s boot device to CDrom</h2>

<p>Set to boot from CDrom</p>

<p class="codetext">vm.update_boot_device &lt;VM NAME&gt; disk_addr=&lt;CDROM BUS&gt;</p>

<p class="codetext">Example: vm.update_boot_device testVM disk_addr=ide.0</p>

<h2>Mount ISO to CDrom</h2>

 <p class="codedescription">Description: Mount ISO to VM cdrom</p>

<p>Steps:</p>

<p>1. Upload ISOs to container</p>

<p>2. Enable whitelist for client IPs</p>

<p>3. Upload ISOs to share</p>

<p>Create CDrom with ISO</p>

<p class="codetext">vm.disk_create &lt;VM NAME&gt; clone_nfs_file=&lt;PATH TO ISO&gt; cdrom=true</p>

<p class="codetext">Example: vm.disk_create testVM clone_nfs_file=/default/ISOs/myfile.iso cdrom=true</p>

<p>If a CDrom is already created just mount it</p>

<p class="codetext">vm.disk_update &lt;VM NAME&gt; &lt;CDROM BUS&gt; clone_nfs_file&lt;PATH TO ISO&gt;</p>

<p class="codetext">Example: vm.disk_update atestVM1 ide.0 clone_nfs_file=/default/ISOs/myfile.iso</p>

<h2>Detach ISO from CDrom</h2>

 <p class="codedescription">Description: Remove ISO from CDrom</p>

<p class="codetext">vm.disk_update &lt;VM NAME&gt; &lt;CDROM BUS&gt; empty=true</p>

<h2>Power on VM(s)</h2>

 <p class="codedescription">Description: Power on VM(s)</p>

<p class="codetext">vm.on &lt;VM NAME(S)&gt;</p>

<p class="codetext">Example: vm.on testVM</p>

<p>Power on all VMs</p>

<p class="codetext">Example: vm.on *</p>

<p>Power on range of VMs</p>

<p class="codetext">Example: vm.on testVM[01..99]</p>
</section>

<section data-type="sect1">
<h1>NCLI</h1>

<p>NOTE: All of these actions can be performed via the HTML5 GUI and REST API.&nbsp; I just use these commands as part of my scripting to automate tasks.</p>

<h2>Add subnet to NFS whitelist</h2>

<p class="codedescription">Description: Adds a particular subnet to the NFS whitelist</p>

<p class="codetext">ncli cluster add-to-nfs-whitelist ip-subnet-masks=10.2.0.0/255.255.0.0</p>

<h2>Display Nutanix Version</h2>

 <p class="codedescription">Description: Displays the current version of the Nutanix software</p>

<p class="codetext">ncli cluster version</p>

<h2>Display hidden NCLI options</h2>

 <p class="codedescription">Description: Displays the hidden ncli commands/options</p>

<p class="codetext">ncli helpsys listall hidden=true [detailed=false|true]</p>

<h2>List Storage Pools</h2>

 <p class="codedescription">Description: Displays the existing storage pools</p>

<p class="codetext">ncli sp ls</p>

<h2>List containers</h2>

 <p class="codedescription">Description: Displays the existing containers</p>

<p class="codetext">ncli ctr ls</p>

<h2>Create container</h2>

<p class="codedescription">Description: Creates a new container</p>

<p class="codetext">ncli ctr create name=&lt;NAME&gt; sp-name=&lt;SP NAME&gt;</p>

<h2>List VMs</h2>

 <p class="codedescription">Description: Displays the existing VMs</p>

<p class="codetext">ncli vm ls</p>

<h2>List public keys</h2>

 <p class="codedescription">Description: Displays the existing public keys</p>

<p class="codetext">ncli cluster list-public-keys</p>

<h2>Add public key</h2>

 <p class="codedescription">Description: Adds a public key for cluster access</p>

<p>SCP private key to CVM</p>

<p>Add private key to cluster</p>

<p class="codetext">ncli cluster add-public-key name=myPK file-path=~/mykey.pub</p>

<h2>Remove public key</h2>

 <p class="codedescription">Description: Removes a public key for cluster access</p>

<p class="codetext">ncli cluster remove-public-keys name=myPK</p>

<h2>Create protection domain</h2>

 <p class="codedescription">Description: Creates a protection domain</p>

<p class="codetext">ncli pd create name=&lt;NAME&gt;</p>

<h2>Create remote site</h2>

 <p class="codedescription">Description: Create a remote site for replication</p>

<p class="codetext">ncli remote-site create name=&lt;NAME&gt; address-list=&lt;Remote Cluster IP&gt;</p>

<h2>Create protection domain for all VMs in container</h2>

 <p class="codedescription">Description: Protect all VMs in the specified container</p>

<p class="codetext">ncli pd protect name=&lt;PD NAME&gt; ctr-id=&lt;Container ID&gt; cg-name=&lt;NAME&gt;</p>

<h2>Create protection domain with specified VMs</h2>

 <p class="codedescription">Description: Protect the VMs specified</p>

<p class="codetext">ncli pd protect name=&lt;PD NAME&gt; vm-names=&lt;VM Name(s)&gt; cg-name=&lt;NAME&gt;</p>

<h2>Create protection domain for DSF files (aka vDisk)</h2>

 <p class="codedescription">Description: Protect the DSF Files specified</p>

<p class="codetext">ncli pd protect name=&lt;PD NAME&gt; files=&lt;File Name(s)&gt; cg-name=&lt;NAME&gt;</p>

<h2>Create snapshot of protection domain</h2>

 <p class="codedescription">Description: Create a one-time snapshot of the protection domain</p>

<p class="codetext">ncli pd add-one-time-snapshot name=&lt;PD NAME&gt; retention-time=&lt;seconds&gt;</p>

<h2>Create snapshot and replication schedule to remote site</h2>

 <p class="codedescription">Description: Create a recurring snapshot schedule and replication to n remote sites</p>

<p class="codetext">ncli pd set-schedule name=&lt;PD NAME&gt; interval=&lt;seconds&gt; retention-policy=&lt;POLICY&gt; remote-sites=&lt;REMOTE SITE NAME&gt;</p>

<h2>List replication status</h2>

 <p class="codedescription">Description: Monitor replication status</p>

<p class="codetext">ncli pd list-replication-status</p>

<h2>Migrate protection domain to remote site</h2>

 <p class="codedescription">Description: Fail-over a protection domain to a remote site</p>

<p class="codetext">ncli pd migrate name=&lt;PD NAME&gt; remote-site=&lt;REMOTE SITE NAME&gt;</p>

<h2>Activate protection domain</h2>

 <p class="codedescription">Description: Activate a protection domain at a remote site</p>

<p class="codetext">ncli pd activate name=&lt;PD NAME&gt;</p>

<h2>Enable DSF Shadow Clones</h2>

 <p class="codedescription">Description: Enables the DSF Shadow Clone feature</p>

<p class="codetext">ncli cluster edit-params enable-shadow-clones=true</p>

<h2>Enable Dedup for vDisk</h2>

 <p class="codedescription">Description: Enables fingerprinting and/or on disk dedup for a specific vDisk</p>

<p class="codetext">ncli vdisk edit name=&lt;VDISK NAME&gt; fingerprint-on-write=&lt;true/false&gt; on-disk-dedup=&lt;true/false&gt;</p>
</section>

<section data-type="sect1">
<h1>PowerShell CMDlets</h1>

<p>The below will cover the Nutanix PowerShell CMDlets, how to use them and some general background on Windows PowerShell.</p>

<h2>Basics</h2>

<p>Windows PowerShell is a powerful shell (hence the name ;P) and scripting language built on the .NET framework.&nbsp; It is a very simple to use language and is built to be intuitive and interactive.&nbsp; Within PowerShell there are a few key constructs/Items:</p>

<h2>CMDlets</h2>

<p>CMDlets are commands or .NET classes which perform a particular operation.&nbsp; They are usually conformed to the Getter/Setter methodology and typically use a &lt;Verb&gt;-&lt;Noun&gt; based structure.&nbsp; For example: Get-Process, Set-Partition, etc.</p>

<h2>Piping or Pipelining</h2>

<p>Piping is an important construct in PowerShell (similar to its use in Linux) and can greatly simplify things when used correctly.&nbsp; With piping you’re essentially taking the output of one section of the pipeline and using that as input to the next section of the pipeline.&nbsp; The pipeline can be as long as required (assuming there remains output which is being fed to the next section of the pipe). A very simple example could be getting the current processes, finding those that match a particular trait or filter and then sorting them:</p>

<p class="codetext">Get-Service | where {$_.Status -eq "Running"} | Sort-Object Name</p>

<p>Piping can also be used in place of for-each, for example:</p>

<p class="codetext"># For each item in my array
<br/>
$myArray | %{
<br/>
&nbsp; # Do something
<br/>
}</p>

<h2>Key Object Types</h2>

<p>Below are a few of the key object types in PowerShell.&nbsp; You can easily get the object type by using the .getType() method, for example: $someVariable.getType() will return the objects type.</p>

<h2>Variable</h2>

<p class="codetext">$myVariable = "foo"</p>

<p class="note">Note: You can also set a variable to the output of a series or pipeline of commands:</p>

<p class="codetext">$myVar2 = (Get-Process | where {$_.Status -eq "Running})</p>

<p>In this example the commands inside the parentheses will be evaluated first then variable will be the outcome of that.</p>

<h2>Array</h2>

<p class="codetext">$myArray = @("Value","Value")</p>

<p class="note">Note: You can also have an array of arrays, hash tables or custom objects</p>

<h2>Hash Table</h2>

<p class="codetext">$myHash = @{"Key" = "Value";"Key" = "Value"}</p>

<h2>Useful commands</h2>

<p>Get the help content for a particular CMDlet (similar to a man page in Linux)</p>

<p class="codetext">Get-Help &lt;CMDlet Name&gt;</p>

<p class="codetext">Example: Get-Help Get-Process</p>

<p>List properties and methods of a command or object</p>

<p class="codetext">&lt;Some expression or object&gt; | Get-Member</p>

<p class="codetext">Example: $someObject | Get-Member</p>

<h2>Core Nutanix CMDlets and Usage</h2>

<p>Download Nutanix CMDlets Installer The Nutanix CMDlets can be downloaded directly from the Prism UI (post 4.0.1) and can be found on the drop down in the upper right hand corner:</p>

<figure class="small"><img alt="" class="iimagesv2cmdlets_dlpng" src="imagesv2/cmdlets_dl.png" />
<figcaption>Prism CMDlets Installer Link</figcaption>
</figure>

<h2>Load Nutanix Snappin</h2>

<p>Check if snappin is loaded and if not, load</p>

<p class="codetext">if ( (Get-PSSnapin -Name NutanixCmdletsPSSnapin -ErrorAction SilentlyContinue) -eq $null )
<br/>
{
<br/>
&nbsp;&nbsp;&nbsp; Add-PsSnapin NutanixCmdletsPSSnapin
<br/>
}</p>

<h2>List Nutanix CMDlets</h2>

<p class="codetext">Get-Command | Where-Object{$_.PSSnapin.Name -eq "NutanixCmdletsPSSnapin"}</p>

<h2>Connect to a Acropolis cluster</h2>

<p class="codetext">Connect-NutanixCluster -Server $server -UserName "myuser" -Password "myuser" -AcceptInvalidSSLCerts</p>

<p>Or secure way prompting user for password</p>

<p class="codetext">Connect-NutanixCluster -Server $server -UserName "myuser" -Password (Read-Host "Password: ") -AcceptInvalidSSLCerts</p>

<h2>Get Nutanix VMs matching a certain search string</h2>

<p>Set to variable</p>

<p class="codetext">$searchString = "myVM"
<br/>
$vms = Get-NTNXVM | where {$_.vmName -match $searchString}</p>

<p>Interactive</p>

<p class="codetext">Get-NTNXVM | where {$_.vmName -match "myString"}</p>

<p>Interactive and formatted</p>

<p class="codetext">Get-NTNXVM | where {$_.vmName -match "myString"} | ft</p>

<h2>Get Nutanix vDisks</h2>

<p>Set to variable</p>

<p class="codetext">$vdisks = Get-NTNXVDisk</p>

<p>Interactive</p>

<p class="codetext">Get-NTNXVDisk</p>

<p>Interactive and formatted</p>

<p class="codetext">Get-NTNXVDisk | ft</p>

<h2>Get Nutanix Containers</h2>

<p>Set to variable</p>

<p class="codetext">$containers = Get-NTNXContainer</p>

<p>Interactive</p>

<p class="codetext">Get-NTNXContainer</p>

<p>Interactive and formatted</p>

<p class="codetext">Get-NTNXContainer | ft</p>

<h2>Get Nutanix Protection Domains</h2>

<p>Set to variable</p>

<p class="codetext">$pds = Get-NTNXProtectionDomain</p>

<p>Interactive</p>

<p class="codetext">Get-NTNXProtectionDomain</p>

<p>Interactive and formatted</p>

<p class="codetext">Get-NTNXProtectionDomain | ft</p>

<h2>Get Nutanix Consistency Groups</h2>

<p>Set to variable</p>

<p class="codetext">$cgs = Get-NTNXProtectionDomainConsistencyGroup</p>

<p>Interactive</p>

<p class="codetext">Get-NTNXProtectionDomainConsistencyGroup</p>

<p>Interactive and formatted</p>

<p class="codetext">Get-NTNXProtectionDomainConsistencyGroup | ft</p>

<h2>Resources and Scripts:</h2>

<ul>
	<li>Nutanix Github - <a href="https://github.com/nutanix/Automation" target="_blank">https://github.com/nutanix/Automation</a></li>
	<li>Manually Fingerprint vDisks - <a href="http://bit.ly/1syOqch" target="_blank">http://bit.ly/1syOqch</a></li>
	<li>vDisk Report - <a href="http://bit.ly/1r34MIT" target="_blank">http://bit.ly/1r34MIT</a></li>
	<li>Protection Domain Report - <a href="http://bit.ly/1r34MIT" target="_blank">http://bit.ly/1r34MIT</a></li>
	<li>Ordered PD Restore - <a href="http://bit.ly/1pyolrb" target="_blank">http://bit.ly/1pyolrb</a></li>
</ul>

<p>You can find more scripts on the Nutanix Github located at <a href="https://github.com/nutanix" target="_blank">https://github.com/nutanix</a></p>
</section>
</section>

<section data-type="chapter">
<h1>Integrations</h1>

<section data-type="sect1">
<h1>OpenStack</h1>

<p><a href="https://www.openstack.org/">OpenStack </a>is an open source platform for managing and building clouds. &nbsp;It is primarily broken into the front-end (dashboard and API) and infrastructure services (compute, storage, etc.).</p>

<p>The OpenStack and Nutanix solution is composed of two main components</p>

<ul>
	<li>OpenStack Controller (OSC)
		<ul>
			<li>An existing, or newly provisioned VM or host hosting the OpenStack UI and OpenStack services.  Handles all OpenStack API calls.</li>
		</ul>
	</li>
	<li>Acropolis Services VM (SVM)
		<ul>
			<li>A helper VM which is responsible to taking OpenStack RPCs from the OpenStack Controller and translates them into native Acropolis API calls.</li>
		</ul>
	</li>
</ul>

<p>The OpenStack Controller can be an existing VM / host, or deployed as part of the OpenStack on Nutanix solution.  The Acropolis SVM is a helper VM which is deployed as part of the Nutanix OpenStack solution.</p>

<p>The client communicates with the OpenStack Controller using their expected methods (Web UI / HTTP or API) and the OpenStack controller communicates with the Acropolis SVM which translates the requests into native Acropolis REST API calls using the OpenStack Driver.</p>

<p>The figure shows a high-level overview of the communication:</p>

<figure><img alt="" src="imagesv2/openstack_overview.png" />
<figcaption>OpenStack + Acropolis Services VM</figcaption>
</figure>

<div data-type="note" class="note">
<h1>Supported OpenStack Controllers</h1>

<p>The current solution (as of 4.5.1) requires an OpenStack Controller on version K or later.</p>
</div>

<p>The table shows a high-level conceptual role mapping:</p>

<table>
  <tr>
    <th>Item</th>
    <th>Role</th>
    <th>OpenStack Controller</th>
    <th>Acropolis SVM</th>
    <th>Acropolis cluster</th>
    <th>External Source</th>
  </tr>
  <tr>
    <td>Tenant Dashboard</td>
    <td>User interface and API</td>
    <td>X</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Orchestration</td>
    <td>Object CRUD and lifecycle management</td>
    <td>X</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Quotas</td>
    <td>Resource controls and limits</td>
    <td>X</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Users, Groups and Roles</td>
    <td>Role based access control (RBAC)</td>
    <td>X</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>SSO</td>
    <td>Single-sign on</td>
    <td>X</td>
    <td></td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Platform Integration</td>
    <td>OpenStack to Nutanix integration</td>
    <td></td>
    <td>X</td>
    <td></td>
    <td></td>
  </tr>
  <tr>
    <td>Infrastructure Services</td>
    <td>Target infrastructure (compute, storage, network)</td>
    <td></td>
    <td></td>
    <td>X</td>
    <td>X</td>
  </tr>
  <tr>
    <td>Image Repo</td>
    <td>Repository for source images</td>
    <td></td>
    <td></td>
    <td>X</td>
    <td>X</td>
  </tr>
  <tr>
    <td>Image Cache</td>
    <td>Local cache for external images</td>
    <td></td>
    <td></td>
    <td>X</td>
    <td></td>
  </tr>
</table>

<section data-type="sect2">
<h2>Components and Integration</h2>

<p>OpenStack is composed of a set of components which are responsible for serving various infrastructure functions.  Some of these funcitons will be hosted by the OpenStack Controller and some will be hosted by the Acropolis SVM.</p>

<p>The table shows the core OpenStack components and role mapping:</p>

<table>
  <tr>
    <th>Component</th>
    <th>Role</th>
    <th>OpenStack Controller</th>
    <th>Acropolis SVM</th>
  </tr>
  <tr>
    <td>Keystone</td>
    <td>Identity service</td>
    <td>X</td>
    <td></td>
  </tr>
  <tr>
    <td>Horizon</td>
    <td>Dashboard and UI</td>
    <td>X</td>
    <td></td>
  </tr>
  <tr>
    <td>Nova</td>
    <td>Compute</td>
    <td></td>
    <td>X</td>
  </tr>
  <tr>
    <td>Swift</td>
    <td>Object storage</td>
    <td>X</td>
    <td>X</td>
  </tr>
  <tr>
    <td>Cinder</td>
    <td>Block storage</td>
    <td></td>
    <td>X</td>
  </tr>
  <tr>
    <td>Glance</td>
    <td>Image service</td>
    <td>X</td>
    <td>X</td>
  </tr>
  <tr>
    <td>Neutron</td>
    <td>Networking</td>
    <td></td>
    <td>X</td>
  </tr>
	<tr>
    <td>Others</td>
    <td>All other components</td>
    <td>X</td>
    <td></td>
  </tr>
</table>

<p>The figure shows a more detailed view of the OpenStack components and communication:</p>

<figure><img alt="" class="iimagesv2openstack_commarch2png" src="imagesv2/openstack_commarch3.png" />
<figcaption>OpenStack + Nutanix API Communication</figcaption>
</figure>

<p>
	In the following sections we will go through some of the main OpenStack components and how they are integrated into the Nutanix platform.
</p>

<section data-type="sect3">
<h3>Nova</h3>
<p>
	Nova is the compute engine and scheduler for the OpenStack platform.  The OpenStack Controller will run the majority of the Nova services and each Acropolis SVM runs the Nova-compute service.
</p>

<p>
	You can view the Nova services using the OpenStack portal under 'Admin'->'System'->'System Information'->'Compute Services'.
</p>

<p>The figure shows the Nova services, host and state:</p>

<figure class="large"><img alt="" src="imagesv2/openstack_nova_services.png" />
<figcaption>OpenStack Nova Services</figcaption>
</figure>

<p>
	Each Acropolis Services VM acts as a compute host and every Acropolis cluster will act as a single hypervisor host eligible for scheduling OpenStack instances.  The Nova scheduler decides which compute host (i.e. Acropolis SVM) to place the instances based upon the selected availability zone.  These requests will be sent to the selected Acropolis SVM which will forward the request to the target host's (i.e. Acropolis cluster) Acropolis scheduler.  The Acropolis scheduler will then determine optimal node placement within the cluster.  Individual nodes within a cluster are not exposed to OpenStack.
</p>

<p>
	You can view the compute and hypevisor hosts using the OpenStack portal under 'Admin'->'System'->'Hypervisors'.
</p>

<p>The figure shows the Acropolis SVM as the compute host:</p>

<figure><img alt="" src="imagesv2/openstack_nova_computehost.png" />
<figcaption>OpenStack Compute Host</figcaption>
</figure>

<p>The figure shows the Acropolis cluster as the hypervisor host:</p>

<figure class="large"><img alt="" src="imagesv2/openstack_nova_hypervisorhost.png" />
<figcaption>OpenStack Hypervisor Host</figcaption>
</figure>

<p>
	As you can see from the previous image the full cluster resources are seen in a single hypervisor host.
</p>

</section>

<section data-type="sect3">
<h3>Swift</h3>
<p>
	Swift in an object store used to store and retrieve files.  This is currently only leveraged for backup / restore of snapshots and images.
</p>
</section>

<section data-type="sect3">
<h3>Cinder</h3>
<p>
	Cinder is OpenStack's volume component for exposing iSCSI targets.  Cinder leverages the Acropolis Volumes API in the Nutanix solution.  These volumes are attached to the instance(s) directly as block devies (as compared to in-guest).
</p>

<p>
	You can view the Cinder services using the OpenStack portal under 'Admin'->'System'->'System Information'->'Block Storage Services'.
</p>

<p>The figure shows the Cinder services, host and state:</p>

<figure class="large"><img alt="" src="imagesv2/openstack_cinder_services.png" />
<figcaption>OpenStack Cinder Services</figcaption>
</figure>

</section>

<section data-type="sect3">
<h3>Glance / Image Repo</h3>
<p>
	Glance is the image store for OpenStack and shows the available images for provisioning.  Images can include ISOs, disks, and snapshots.
</p>
<p>
	The Image Repo is the repository storing available images published by Glance.  These can be located within the Nutanix environment or by an external source.  When the images are hosted on the Nutanix platform, they will be published to the OpenStack controller via Glance on the SVM.  In cases where the Image Repo exists only on an external source, Glance will be hosted by the OpenStack Controller and the Image Cache will be leveraged on the Acropolis cluster(s).
</p>
<p>
	 Glance is enabled on a per-cluster basis and will always exist with the Image Repo.  When Glance is enabled on multiple clusters the Image Repo will span those clusters and images created via the OpenStack Portal will be propogated to all clusters running Glance.  Those clusters not hosting Glance will cache the images locally using the Image Cache.
</p>

<div data-type="note" class="note">
<h1>Pro tip</h1>

<p>For larger deployments the Image Repo should run on at least two Acropolis clusters per site.  This will provide Image Repo HA in the case of a cluster outage and ensure the images will always be available when not in the Image Cache.</p>
</div>

<p>
	When external sources host the Image Repo / Glance, Nova will be responsible for handling data movement from the external source to the target Acropolis cluster(s).  In this case the Image Cache will be leveraged on the target Acropolis cluster(s) to cache the image locally for any subsequent provisioning requsts for the image.
</p>
</section>

<section data-type="sect3">
<h3>Neutron</h3>
<p>
	Neutron is the networking component of OpenStack and responsible for network configuration.  The Acropolis SVM allows network CRUD operations to be performed by the OpenStack portal and will then make the required changes in Acropolis.
</p>

<p>
	You can view the Neutron services using the OpenStack portal under 'Admin'->'System'->'System Information'->'Network Agents'.
</p>

<p>The figure shows the Neutron services, host and state:</p>

<figure class="large"><img alt="" src="imagesv2/openstack_neutron_services.png" />
<figcaption>OpenStack Neutron Services</figcaption>
</figure>
<p>
	Neutron will assign IP addresses to instances when they are booted.  In this case Acropolis will recieve a desired IP address for the VM which will be allocated.  When the VM performs a DHCP request the Acropolis Master will respond to the DHCP request on a private VXLAN as usual with Acropolis Hypervisor.
</p>

<div data-type="note" class="note">
<h1>Supported Network Types</h1>

<p>Currently only Local and VLAN network types are supported.</p>
</div>

</section>
</section>
<section data-type="sect2">
<h2>Design and Deployment</h2>

<section data-type="sect3">
<h3>Topology and Site Design</h3>
<p>
	For large scale cloud deployments it is important to leverage a delivery topology that will be distributed and meet the requirements of the end-users while providing flexibility and locality.
</p>

<p>
	OpenStack leverages the following high-level constructs which are defined below:
</p>

<ul>
	<li>
		Region
		<ul>
			<li>
				A geographic landmass or area where multiple Availability Zones (sites) are located.  These can include regions like US-Northwest or US-West.
			</li>
		</ul>
	</li>
	<li>
		Availability Zone (AZ)
		<ul>
			<li>
				A specific site or datacenter location where cloud services are hosted.  These can include sites like US-Northwest-1 or US-West-1.
			</li>
		</ul>
	</li>
	<li>
		Host Aggregate
		<ul>
			<li>
				A group of compute hosts, can be a row, aisle or equivalent to the site / AZ.
			</li>
		</ul>
	</li>
	<li>
		Compute Host
		<ul>
			<li>
				An Acropolis Services VM which is running the nova-compute service.
			</li>
		</ul>
	</li>
	<li>
		Hypervisor Host
		<ul>
			<li>
				An Acropolis cluster (seen as a single host).
			</li>
		</ul>
	</li>
</ul>

<p>
	The figure shows the high-level relationship of the constructs:
</p>

<figure><img alt="" src="imagesv2/openstack_regions.png" />
<figcaption>OpenStack - Deployment Layout</figcaption>
</figure>

<p>
	The figure shows an example application of the constructs:
</p>

<figure><img alt="" src="imagesv2/openstack_regions_example.png" />
<figcaption>OpenStack - Deployment Layout - Example</figcaption>
</figure>

<p>
	You can view and manage hosts, host aggregates and availability zones using the OpenStack portal under 'Admin'->'System'->'Host Aggregates'.
</p>

<p>The figure shows the host aggregates, availability zones and hosts:</p>

<figure class="large"><img alt="" src="imagesv2/openstack_hostagg_az.png" />
<figcaption>OpenStack Host Aggregates and Availability Zones</figcaption>
</figure>

</section>

<section data-type="sect3">
<h3>Services Design and Scaling</h3>

<p>For larger deployments it is recommended to have multiple Acropolis SVMs connected to the OpenStack Controller abstracted by a load balancer. This allows for HA and of the SVMs as well as distribution of transactions. The SVM(s) don't contain any state information allowing them to be scaled.</p>

<p>The figure shows an example of scaling SVMs for a single site:</p>

<figure><img alt="" class="iimagesv2openstack_svmhapng" src="imagesv2/openstack_svmha.png" />
<figcaption>OpenStack - SVM Load Balancing</figcaption>
</figure>

<p>For environments spanning multiple sites the OpenStack Controller will talk to multiple Acropolis SVMs across sites.</p>

<p>The figure shows an example of the deployment across multiple sites:</p>
<figure><img alt="" src="imagesv2/openstack_siteha.png" />
<figcaption>OpenStack - Multi-Site</figcaption>
</figure>
</section>

<section data-type="sect3">
<h3>Deployment</h3>
<h4>Acropolis Services VM</h4>
<p>
	The Acropolis Services VM can be deployed using the following steps:
</p>
<ol>
  <li>Import Services VM disk image to Acropolis cluster
		<ul>
			<li>
				Copy Services VM disk image to Acropolis Cluster
				<p>SCP image to any CVM IP on port 2222</p>
				<p class="codetext">image.create &lt;IMAGE_NAME&gt; clone_from_vmdisk=&lt;IMAGE_PATH&gt; container=&lt;CONTAINER_NAME&gt;</p>
			</li>
			<li>
				OR Import disk image using Images API
				<p class="codetext">image.create &lt;IMAGE_NAME&gt; source_url=&lt;SOURCE_URL&gt; container=&lt;CONTAINER_NAME&gt;</p>
			</li>
		</ul>
	</li>
  <li>Create Acropolis VM for Services VM</li>
		<p class="codetext">vm.create &lt;VM_NAME&gt; num_vcpus=2 memory=16G<br/>
		vm.disk_create &lt;VM_NAME&gt; clone_from_image=&lt;IMAGE_NAME&gt;<br/>
		vm.nic_create &lt;VM_NAME&gt; network=&lt;NETWORK_NAME&gt;</p>
  <li>SSH to Service VM using provided credentials</li>
  <li>Register local OpenStack driver service
		<p class="codetext">acc --add=service --name=&lt;ASVM_NAME&gt; --ip=&lt;ASVM_IP&gt; --username=root --password=admin</p>
	</li>
  <li>Register OpenStack Controller</li>
		<p class="codetext">acc --add=controller --name=&lt;OS_CONTROLLER_NAME&gt; --ip=&lt;OS_CONTROLLER_IP&gt; --username=admin --password=admin</p>
  <li>Register Acropolis Cluster(s)</li>
		<p class="codetext">acc --add=cluster --name=&lt;CLUSTER_NAME&gt; --ip=&lt;CLUSTER_IP&gt; --username=&lt;PRISM_USER&gt; --password=&lt;PRISM_PASSWORD&gt; --vnc=8081</p>
		<li>
			Add Keystone endpoint for glance
			<ol>
				<li>
					Get Glance service id
					<p class="codetext">
						keystone service-list
					</p>
				</li>
				<li>
					Add serice endpoint for Glance
					<p class="codetext">
						keystone endpoint-create \ <br/>
					  --service-id=&lt;GLANCE_SERVICE_ID&gt; \ <br/>
					  --publicurl=http://&lt;ASVM_IP&gt;:9292 \ <br/>
					  --internalurl=http://&lt;ASVM_IP&gt;:9292 \ <br/>
					  --region=&lt;REGION_NAME&gt; \ <br/>
					  --adminurl=http://&lt;ASVM_IP&gt;:9292
					</p>
				</li>
			</ol>
		</li>
		<li>
			Add Keystone endpoint for Neutron
			<ol>
				<li>
					Get Neutron service id
					<p class="codetext">
						keystone service-list
					</p>
				</li>
				<li>
					Add serice endpoint for Neutron
					<p class="codetext">
						keystone endpoint-create \ <br/>
					  --service-id=&lt;GLANCE_SERVICE_ID&gt; \ <br/>
					  --publicurl=http://&lt;ASVM_IP&gt;:9696 \ <br/>
					  --internalurl=http://&lt;ASVM_IP&gt;:9696 \ <br/>
					  --region=&lt;REGION_NAME&gt; \ <br/>
					  --adminurl=http://&lt;ASVM_IP&gt;:9696
					</p>
				</li>
			</ol>
		</li>
		<li>
			Edit nova.conf with new Services VM IP of Glance host
		</li>
		<li>
			Edit cinder.conf with Services VM IP of Glance host
		</li>
		<li>
			Restart Nova services
		</li>
		<li>
			Restart Cinder services
		</li>
</ol>

</section>

<section data-type="sect2">
<h2>Troubleshooting &amp; Advanced Administration</h2>

<section data-type="sect3">
<h3>Key log locations</h3>
<table>
  <tr>
    <th>Component</th>
    <th>Key Log Location(s)</th>
  </tr>
  <tr>
    <td>Keystone</td>
    <td>/var/log/keystone/keystone.log</td>
  </tr>
  <tr>
    <td>Horizon</td>
    <td>/var/log/horizon/horizon.log</td>
  </tr>
  <tr>
    <td>Nova</td>
    <td>/var/log/nova/nova-api.log<br>/var/log/nova/nova-scheduler.log<br>/var/log/nova/nove-compute.log*</td>
  </tr>
  <tr>
    <td>Swift</td>
    <td>/var/log/swift/swift.log</td>
  </tr>
  <tr>
    <td>Cinder</td>
    <td>/var/log/cinder/api.log<br>/var/log/cinder/scheduler.log<br>/var/log/cinder/volume.log</td>
  </tr>
  <tr>
    <td>Glance</td>
    <td>/var/log/glance/api.log<br>/var/log/glance/registry.log</td>
  </tr>
  <tr>
    <td>Neutron</td>
    <td>/var/log/neutron/server.log<br>/var/log/neutron/dhcp-agent.log*<br>/var/log/neutron/l3-agent.log*<br>/var/log/neutron/metadata-agent.log*<br>/var/log/neutron/openvswitch-agent.log*</td>
  </tr>
</table>
<p>
	Logs marked with * are on the Acropolis SVM only.
</p>

</section>

<section data-type="sect3">
<h3>Command Reference</h3>

<p>Load Keystone source (perform before running other commands)</p>

<p class="codetext">source keystonerc_admin</p>

<p>List Keystone services</p>

<p class="codetext">keystone service-list</p>

<p>List Keystone endpoints</p>

<p class="codetext">keystone endpoint-list</p>

<p>Create Keystone endpoint</p>

<p class="codetext">
	keystone endpoint-create \ <br/>
  --service-id=&lt;SERVICE_ID&gt; \ <br/>
  --publicurl=http://&lt;IP&#58;PORT&gt; \ <br/>
  --internalurl=http://&lt;IP&#58;PORT&gt; \ <br/>
  --region=&lt;REGION_NAME&gt; \ <br/>
  --adminurl=http://&lt;IP:PORT&gt; <br/>
</p>

<p>List Nova instances</p>

<p class="codetext">nova list</p>

<p>Show instance details</p>

<p class="codetext">nova show &lt;INSTANCE_NAME&gt;</p>

<p>List Nova hypersivor hosts</p>

<p class="codetext">nova hypervisor-list</p>

<p>Show hyprevisor host details</p>

<p class="codetext">nova hypervisor-show &lt;HOST_ID&gt;</p>

<p>List Glance images</p>

<p class="codetext">glance image-list</p>

<p>Show Glance image details</p>

<p class="codetext">glance image-show &lt;IMAGE_ID&gt;</p>

</section>

</section>
</section>
</section>
</section>
</div>
